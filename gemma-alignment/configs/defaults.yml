# Gemma Alignment - Default Configuration
#
# This file contains default values for all configuration options.
# Specific experiment configs override these defaults.

task: safety
dataset_path: data/datasets
seed: 42
device: auto
debug: false

model:
  base_checkpoint: google/gemma-3-270m-it
  size: 270m
  peft_type: lora
  peft_rank: 8
  peft_alpha: 16
  peft_dropout: 0.1
  peft_target_modules:
    - q_proj
    - v_proj
    - k_proj
    - o_proj
  load_in_4bit: false
  load_in_8bit: false

training:
  mode: sft
  epochs: 3
  batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 5.0e-5
  weight_decay: 0.01
  warmup_ratio: 0.1
  max_grad_norm: 1.0
  max_seq_length: 512
  fp16: false
  bf16: true

rl:
  algorithm: ppo
  rollout_size: 64
  num_ppo_epochs: 4
  ppo_clip: 0.2
  entropy_coeff: 0.01
  value_coeff: 0.5
  kl_coef: 0.1
  gamma: 1.0
  lam: 0.95
  target_kl: null
  dpo_beta: 0.1

reward:
  type: hybrid
  alpha: 0.5
  beta: 0.5
  normalize_rewards: true
  clip_rewards: 10.0
  heuristic:
    toxicity_threshold: 0.3
    toxicity_weight: 0.5
    length_penalty: 0.0
    repetition_penalty: 0.1
  trainable:
    architecture: small-bert
    hidden_size: 768
    num_layers: 3
    learning_rate: 2.0e-5
    checkpoint_path: null

logging:
  wandb_enabled: false
  wandb_project: gemma-alignment
  wandb_entity: null
  log_interval: 50
  eval_interval: 500
  save_interval: 1000
  output_dir: outputs
  checkpoint_dir: checkpoints
