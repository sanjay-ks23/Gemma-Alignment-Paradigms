# Staged SFT -> PPO configuration

model:
  base_checkpoint: google/gemma-3-270m-it
  peft_type: lora
  peft_rank: 8

training:
  mode: staged
  epochs: 3
  batch_size: 4

rl:
  algorithm: ppo
  ppo_clip: 0.2
